# 20190620

## Big Data

* 빅데이터의 등장 - 최근 데이터 급격히 증가

  데이터가 많으면 분석 쉽다. 어떻게 분석할까? big data

* 빅데이터의 성공례는 많아, 다양한 자동화 공정, 수동 공정에서 도입해서 효과 봐

* 범죄 분석, 결함 분석, 훌루, 넷플릭스, 카약의 비행기표 가격 예상 등 추천시스템에서 많이 쓰이고 있다

* 무어의 법칙시대가 막을 내리는 중, 성능 올리기의 한계

* 싼 컴퓨터 다수 쓰는 것이 scale-out, 적은 수의 값비싼 서버 이용이 scale-up

* 하둡을 많이 사용

  * Apache프로젝트의 MapReduce오픈 소스
  * Hadoop Distribute~~

* 데이터의 폭발적 증가, 데이터 마이닐 기술이 큰 기여, 선진국에서 집중적 투자중, IT강국으로 리더 될 분야

## 프로젝트 설명

### 추천 시스템

* 어느 기업이나 추천은 중요한 부분
* 영화 평점 데이터 이용, 유사 유저 또는 유사 영화 보여 주며 여러 클러 스터링
* 영화 평점 빅데이터를 이용, 추천 시스템의 방법 중 하나인 협업 필터링의 여러 알고리즘들은 파이썬 언어로 효율적으로 구현
* Django를 이용하여 실제 어플리케이션의 UI를 구현하는 방법
* Python언어의 numpy와 scipy라이브러리를 사용 행렬 표현 연산, 기본적 함수 이해 효율적 사용
  * Sparse matrix(희소행열) 형태의 데이터를 array에 그대로 저장하면 메모리도 많이 필요하고 시간도 오래 걸림
  * Python numpy 라이브러리의 행렬 연산과 scipy 라이브러리의 spare matrix format을 이용 하여 효율적인 코딩
* Django, python 구현 MovieLens 영화 데이터의 평점 행렬을 보고 각 유저에 대해서 유사한 유저와 각 영화 별로 유사한 영화들을 보여주는 알고리즘 구현
* 여러가지 클러스터링 알고리즘들을 사용하여 구현
* 유사도에 따른 추천 알고리즘 구현

* 영화 추천 시스템에 대한 이해
* 주요 알고리즘 이해, KNN, Matrix factorization (+ PLSI or LDA)
* 많이 쓰이는 Probabilistic Modeling 기술을 습득
* 영화 평점 외 다른 정보도 이용
* python을 사용 빅데이터 처리 효율적인 코딩 실습
  * numpy를 안쓰면 그냥은 안돌아간다.
  * python제공 broadcasting 기법을 써서 더 효율적으로 행렬 연산
  * Python 의 sparse matrix format을 보완할 수 있는 리스트 구조의 자료 구조로 빠른 sparse 연산
* 개발 환경 구성
  * python 최신 버전, numpy, scypy등 설치

#### K-nearest neighbor(KNN) 알고리즘들

* K명의 유저와 가까운 사람을 고른다.
* 그 사람들이 rating을 얼마나 먹였는지 보여준다.
* 유저 입장, 아이템 입장에서 모두 구할 수 있다.

### 도전적으로 하자면?

* UI구현?
*  예고편, 동영상 등 추천 할때마다 제공
* 멀티 코어, GPU 잘 되게 python 코드 구현
* 영화 줄거리 텍스트만 이용하지 않고 다른 정보 사용
* 기계학습 툴이용 PLSI 대신 딥러닝 알고리즘 접목
* 하둡의 MapReduce 프레임워크 이용 병렬 분상으로 3가지 알고리즘 구현(python도 가능)
* 더 복잡한 실제 데이터를 이용한 추천 시스템 개발
* twitter에서 유저들에게 관심이 가는 tweet massage~twitobi
  * 자신이 follow 한 사람의 관심사도 분석에 들어 간다

### 프로젝트 관련 기초지식

* Clustering 이란?
  * Given:data points and number of desired cluster K, 비슷한 K개 묶음의 데이터 묶음을 찾는 것
  * 백화점 고객의 구매 상품 별로, 추천시 과거 패턴, gene유사도 클러스터링, 텍스트 문서를 주제별로 클러스터링, facebook에서 이미지들을 유사한 이미지들로 클러스터링 등
* K-Means Cluster Algoriths
  * ㅇㄴ



### EM 클러스터링

* Generative model-생성 모델
  * 우리 세상이 어떻게 생겼는지 수학 단계부터 구성 하려는 것
  * 결과를 보고 어떤 상황에서 이 데이터가 만들어지는게 확률이 높은가?
  * 이때 쓰는 알고리즘이 EM 클러스터링
* 어떤 상황에서 나올 수 있는지 미분으로 정보 알아 보고 다시 돌아가고 반복
* 확률 분포를 다양한 가우스 분포의 합으로 나타낸다. 갯수 많아지면 완벽한 가우스 분포로 나타내는 것이 가능
* 가능한 확률 분포를 만들어 내기 위한 K 가우시안 합성 모델
* 각각의 데이터가 만들어질 확률을 통해 원래의 상태를 추측한다.

### PLSI

* 특정 토픽이 나올때 토픽마다 단어가 다르기 때문에 그에 따라 가중치를 만들어서 단어 별로 어떤 단어가 나오는게 나올 확률이 높은가? 는 너무 어렵다. 변수 너무 많아
* 문단이 얼마나 길지 모르니 토픽 하나 골랐다고 봤을 때 단순화를 통해 특정 주제를 골랐을대 특정 단어를 쓸 확률이 높다고 노델링 하는 것이다. 문장이 나올 확률을 수학적으로 계산
* 문서-주제-단어에서 그런 줄거리를 만들 만한 확률을 계산한다. 해당 줄거리가 쓰여질 확률을 계산, 

### Matrix Factorization

* 추천시스템 중 content based filtering method
  * 유저사 구매한 제품 정보 이용, 비슷한 정보 추천
* collaborative filtering method
  * 유저는 비슷한 다른 유저와 동일하게 행동한다는 가정- 다른 유저들이 추천 영향
  * 유저가 점수 매진 item들에 대한 rating을 이용해서 추천
  * memory based - 데이터만 가지고 추천
    * 같은 물건을 산 유저들의 유사도 분석
    * 유사도 높은 유저가 산 것을 추천한다.
  * model based -  최적화 파라미터 처럼 유저마다 vector가 있다고 생각
    * 과거의 rating base로 model제작, 모델로 unseen item 레이팅
    * PLSI 등

### In a nutshell,...

* 영화 평점 데이터를 이용, 유사 유저 또는 유사 영화 보여주며 클러스터링 알고리즘 이용 분석
* 영화 평점 빅데이터를 이용, 추천 시스템의 방법 중 하나인 협업 필터링의 여러 알고리즘들은 파이썬 언어로 효율적으로 구현

### PLSI

* 특정 단어들이 쓰였을때 어떤 식으로 쓰였는가? 추상적일수도있고 아닐 수도있다.
  * 토픽과 글의 단어들을 곱해서 해당 글이 나올 확률을 계산하는 것

### 클러스터링

* 그룹이라는 의미
* 유사도가 높은 유저, 아이템 별로 묶어서 활용한다. 거리가 짧을 수록 좋은 클러스터, 그렇다고 유사도 너무 높이면 클러스터가 나오지 않는다.
* EM 클러스터링은 E스텝과 M스텝으로 나눠진다. 